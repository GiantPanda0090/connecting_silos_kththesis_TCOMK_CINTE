@Book{ref1,
author="{ARNEKVIST, ISAC}
and {OSKAR, STEVE}",
title="Reinforcement learning for robotic manipulation: A case study of knowledge management in projects at a Swedish bank",
abstract="Reinforcement learning was recently successfully used for real-world robotic manipulation tasks, without the need for human demonstration, using a normalized advantage function-algorithm (NAF). Limitations on the shape of the advantage function however poses doubts to what kind of policies can be learned using this method. For similar tasks, convolu- tional neural networks have been used for pose estimation from images taken with fixed-position cameras. For some applications however, this might not be a valid assumption. It was also shown that the quality of policies for robotic tasks severely deteriorates from small camera off- sets. This thesis investigates the use of NAF for a pushing task with clear multi-modal properties. The results are compared with using a determin- istic policy with minimal constraints on the Q-function surface. Methods for pose estimation using convolutional neural networks are further in- vestigated, especially with regards to randomly placed cameras with un- known offsets. By defining the coordinate frame of objects with respect to some visible feature, it is hypothesized that relative pose estimation can be accomplished even when the camera is not fixed and the offset is unknown. NAF is successfully implemented to solve a simple reaching task on a real robotic system where data collection is distributed over several robots, and learning is done on a separate server. Using NAF to learn a pushing task fails to converge to a good policy, both on the real robots and in simulation. Deep deterministic policy gradient (DDPG) is instead used in simulation and successfully learns to solve the task. The learned policy is then applied on the real robots and accomplishes to solve the task in the real setting as well. Pose estimation from fixed position camera images is learned and the policy is still able to solve the task using these estimates. By defining a coordinate frame from an object visible to the camera, in this case the robot arm, a neural network learns to regress the pushable objects pose in this frame without the assump- tion of a fixed camera. However, the precision of the predictions were too inaccurate to be used for solving the pushing task. Further modifi- cations to this approach could however show to be a feasible solution to randomly placed cameras with unknown poses. iv"
}

